name: Update GitHub Pages with Scraped Links

on:
  schedule:
    - cron: "0 * * * *"  # Runs every hour
  workflow_dispatch:

jobs:
  update-pages:
    runs-on: ubuntu-latest

    steps:
      # Checkout repository to access files
      - name: Checkout repository
        uses: actions/checkout@v3

      # Set current timestamp in CST timezone
      - name: Set last updated timestamp in CST timezone
        id: timestamp
        run: |
          export TZ="America/Chicago"
          echo "LAST_UPDATED=$(date +"%B %d, %Y at %I:%M %p %Z")" >> $GITHUB_ENV

      # Fetch and scrape titles and list elements from the target webpage
      - name: Scrape Titles and List Elements
        run: |
          # Define target URL
          URL="https://nirbytes.com/post/1000-proxies-for-school-chromebook-2024"

          # Fetch webpage content
          RESPONSE=$(curl -s "$URL")

          # Extract titles and their corresponding list items
          echo "{" > links.json

          echo "$RESPONSE" | grep -oP '(?<=<h2>).*?(?=</h2>)' | while read -r TITLE; do
            echo "  \"$TITLE\": [" >> links.json

            # Extract list items under each title
            echo "$RESPONSE" | grep -oP '(?<=<li><a href=")[^"]*' | while read -r LINK; do
              echo "    \"$LINK\"," >> links.json
            done

            # Remove trailing comma for each title's list and close the array
            sed -i '$ s/,$//' links.json
            echo "  ]," >> links.json
          done

          # Remove the last comma and close the JSON object
          sed -i '$ s/,$//' links.json
          echo "}" >> links.json

      # Commit and push changes to the repository
      - name: Commit and push changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add links.json
          git commit -m "Auto-update links.json with scraped titles and list elements"
          git push
