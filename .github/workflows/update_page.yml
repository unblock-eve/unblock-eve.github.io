name: Update GitHub Pages with Scraped Links

on:
  schedule:
    - cron: "0 * * * *"  # Runs every hour
  workflow_dispatch:

jobs:
  update-pages:
    runs-on: ubuntu-latest

    steps:
      # Checkout repository to access files
      - name: Checkout repository
        uses: actions/checkout@v3

      # Set current timestamp in CST timezone
      - name: Set last updated timestamp in CST timezone
        id: timestamp
        run: |
          export TZ="America/Chicago"
          echo "LAST_UPDATED=$(date +"%B %d, %Y at %I:%M %p %Z")" >> $GITHUB_ENV

      # Fetch and scrape links and titles from the target webpage
      - name: Scrape Links and Titles
        run: |
          # Define target URL
          URL="https://nirbytes.com/post/1000-proxies-for-school-chromebook-2024"

          # Fetch webpage content
          RESPONSE=$(curl -s "$URL")

          # Use a more robust pattern to extract titles and their associated lists
          echo "{" > links.json
          echo "$RESPONSE" | grep -oP '(?<=<h2>).*?(?=</h2>)' | while read -r TITLE; do
            echo "  \"$TITLE\": [" >> links.json
            LINKS=$(echo "$RESPONSE" | grep -oP "(?<=<li><a href=\")[^\"]*" | head -n 10)
            echo "$LINKS" | while read -r LINK; do
              echo "    \"$LINK\"," >> links.json
            done
            sed -i '$ s/,$//' links.json  # Remove trailing comma for the last link
            echo "  ]," >> links.json
          done
          sed -i '$ s/,$//' links.json  # Remove trailing comma for the last title
          echo "}" >> links.json

      # Commit and push changes to the repository
      - name: Commit and push changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add links.json
          git commit -m "Auto-update links.json with scraped links and titles"
          git push
